{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is punctuation.\\nThe text contains uppercase and lowercase.\\nThere are special characters in the German.\\nThere are duplicate phrases in English with different translations in German.\\nThe file is ordered by sentence length with very long sentences toward the end of the file.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''There is punctuation.\n",
    "The text contains uppercase and lowercase.\n",
    "There are special characters in the German.\n",
    "There are duplicate phrases in English with different translations in German.\n",
    "The file is ordered by sentence length with very long sentences toward the end of the file.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    #open the file as read only\n",
    "    file = open(filename, mode='rt', encoding = 'utf-8')\n",
    "    #read all text\n",
    "    text = file.read()\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into two sentences\n",
    "\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean a list of lines\n",
    "def clean_pairs(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    #prepare translation table for removing punctuation\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            line = normalize('NFD', line).encode('ascii','ignore')\n",
    "            line = line.decode('UTF-8')\n",
    "            #tokenize on white space\n",
    "            line = line.split()\n",
    "            #lowercase\n",
    "            line = [word.lower() for word in line]\n",
    "            #remove punctuation\n",
    "            line = [word.translate(table) for word in line]\n",
    "            #remove non-printable chars from each token\n",
    "            line = [re_print.sub('',w) for w in line]\n",
    "            # remove tokens with numbers in them\n",
    "            line = [word for word in line if word.isalpha()]\n",
    "            #store as a string\n",
    "            clean_pair.append(' '.join(line))\n",
    "        cleaned.append(clean_pair)\n",
    "    return array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename,'wb'))\n",
    "    print('Saved: %s' %filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: clean-all-english-german.pkl\n"
     ]
    }
   ],
   "source": [
    "filename = 'all-english-german.txt'\n",
    "doc = load_doc(filename)\n",
    "\n",
    "pairs = to_pairs(doc)\n",
    "clean_pairs = clean_pairs(pairs)\n",
    "\n",
    "save_clean_data(clean_pairs,'clean-all-english-german.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i work in a bank', 'ich arbeite bei einer bank'], dtype='<U370')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pairs[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(max([len(x) for x in clean_pairs[:50000,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_pairs = clean_pairs[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['youve always been very good to me',\n",
       "       'du bist immer sehr gut zu mir gewesen'], dtype='<U370')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_pairs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english-german-large.pkl\n"
     ]
    }
   ],
   "source": [
    "save_clean_data(large_pairs, 'english-german-large.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2af03d7e22c24bf2e6d190a35b261c407267ffc2225e910495761a73f1323185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
